\chapter{Existing system}
The main source of complexity of existing system are each component dependencies and managing them. Numerous dependencies must be installed on host operating system. The SimBaD project is still under development and new features are being added, and that causes a need for already installed components to be updated. Moreover, updates to host operating system may also evoke a need to update. To facilitate installation and updates of system, some kind of method of managing the project with its dependencies and managing distribution is needed. In the following sections, existing components and its dependencies will be described in more detail, and three methods for host-agnostic installation and managing dependencies will be discssed: custom installation scripts, virtualization and containerization  will be discussed.
\section{Components and its dependencies}
 The program responsible for first simulation step - SimBaD-CLI is written in \textit{C++} using \textit{Boost} libraries. In order to prevent installing tool chain needed to compile this program, pre-build binaries were used.  As the program is linked dynamically, that is, necessary shared libraries are loaded at runtime and must be installed on host operating system. For example, for Linux-based operating systems, to find out all shared libraries required by program executable, the \textit{readelf} command was used. The output of this command is visible on listing \ref{list:readelf}. Those libraries, or their os specific equivalents, need to be distributed along with the executable to enable program to run. 
\begin{lstlisting}[label=list:readelf,caption=The output of readelf command (Tag column ommited), basicstyle=\footnotesize\ttfamily]
root@40fe8913a16f:/# readelf simbad-cli 
Type     Name/Value
(NEEDED) Shared library: [libboost_program_options.so.1.67.0]
(NEEDED) Shared library: [libstdc++.so.6]
(NEEDED) Shared library: [libm.so.6]
(NEEDED) Shared library: [libgcc_s.so.1]
(NEEDED) Shared library: [libc.so.6]
 ...
\end{lstlisting}

The second step of simulation, responsible for analyzing the stream data is an \textit{Apache Spark} program written in Scala. \textit{Apache Spark} is a framework for distributed computing. Assuming that the Scala program is already built to .jar files, to run it, it is necessary to install spark ecosystem - proper versions of \textit{Java}, \textit{Apache Spark} and \textit{Apache Hadoop}, each with its additional dependencies.

The last step of simulation, responsible for visualizing the processed data is a set of \textit{Python} scripts. The script read data from csv and parquet files using \textit{Pyarrow} library, and then generate plots with \textit{Matplotlib} and \textit{Igraph}. Naturally, those libraries depend on another set of libraries, for example \textit{Pyarrow} depends directly on \textit{C++ Arrow} and \textit{Numpy}. 
\newpage
\section{Making the system host agnostic}
Making the programs cross-platform is a difficult tasks. There are several ways to make computer program run on arbitrary platforms.
\subsection{Installing all dependencies}
The first way is to compile the program natively, and install its third-party dependencies on the host system. This approach has several issues, first it is necessary to write installers or maintain packages for every system that we'd want to run the program on. Another issue is that the already existing configurations and installed programs or shared libraries will often have different versions the the ones needed to run program have wrong versions, and changing those versions requires user intervention, and even it it succeeds it may break existing applications. The same issue extends to uninstalling - if user wants to remove program, it's hard to remove its dependencies. Worst case scenario is when program or dependency is not compatible with host and cannot be installed, for example windows programs on Linux, or specific versions of library that are not compatible. Even if somehow all of these pitfalls were avoided, in the long run there are still OS updates that would need to be adjusted for. This leads to another issue - no versioning. Further development of system will lead to changes in its functionality, configuration and dependencies, and that creates a need for self-updating and patching capabilities.  The single most important advantage of this approach is performance - program run natively will have the least abstraction-related overhead, better access to host resources and in turn run faster. 
\subsection{Virtual Machines}
Another approach is virtualization - the process of running an separated environment on a layer separate from actual hardware. This process is enabled by a software called \textit{hypervisor}, that allows to create those separate environments, (also called \textit{Virtual Machines}) on host system. For SimBad project, this allows to create a template or an image of the environment with all of the dependencies and programs installed. From this image a virtual machine can be crated and wherever virtualization software is installed, the simulation process can be run. This solves a problem with writing separate install scripts for each operating system. Due to high degree of separation, it does not interfere with existing programs and libraries on host system and installing it does not break any existing dependencies. The virtual machine separation also solves the uninstalling problem - to completely remove the system from host user only needs to remove \textit{VM} image. 

Though it solves the "create once run anywhere" problem, this approach also has several drawbacks. Apart from all the programs and their dependencies, the image also contains whole operating system, and that increases the memory footprint. Apart from memory use, that simulation startup time also increases - whole another operating OS needs to boot before simulation can start. Additional layer of abstraction also adds some performance overhead. Another issue that, while it allows run the system in a single portable environments, virtualization of whole system makes harder to decouple its components. For example, if one for some reason (such as performance or decoupling) were to separate one of the simulation components into a dedicated machine, a custom virtual machine would have to be created. 
\subsection{Container}
Another solution to managing programs and their dependencies is containerization. It provides the ability to bundle the program and all of its dependencies - libraries, configuration files or binaries in such a way that in a single package (container) that makes it possible to run this programs across in different computer environments. There are several existing containerization solutions, but for the purpose of this comparison the most popular one - Docker was chosen.

Docker is platform that - to quote from the official documentation - " provides the ability to package and run an application in a loosely isolated environment called a container". Aside of containers, it also allows to define abstraction of file systems and networks.  In contrast to virtual machines it does not use hypervisor to separate and isolate processes from one another but instead it uses Linux kernel features, such as namespacing and control groups. This allows for applications running inside of Docker containers to outperform virtual-machines in almost all benchmarks, reaching native performance.  It is lightweight compared to virtual machine - basic alpine Linux image is only 5MB. Another advantage is startup time - docker needs only few seconds to start, compared to few minutes in case of VM. Use of layer-file system enables docker to share layers between containers, for example, the same image with \textit{Debian Stable} + python can be shared between two different containers, thus saving memory. 

Docker has excellent development features. Each image is defined by Dockerfile that specifies all the steps needed to create container. When changes are made to underlying component, the docker image can be build from source to reflect the changes. Docker also has support for versioning with tags and a platform where developers can upload their images - DockerHub. DockerHub makes easy to distribute the images, in case of VMS, some kind of file hosting would be necessary. Another albeit, SimBaD project specific advantage is that there are already several Dockerfiles that define images needed to build or run system components.
The disadvantage of docker is that it relies heavily on Linux and Linux kernel features. There is official support for docker on Windows and Mac OS machines, but on those systems docker runs on minimal Linux virtual machine, and that leads to the same performance drawbacks that is characteristic to virtual machines.
