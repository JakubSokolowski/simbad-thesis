\chapter{Existing system}
\label{chapter:2}
The main source of complexity of existing system are each component dependencies and managing them. Numerous dependencies must be installed on host operating system. The SimBaD project is still under development and new features are being added, and that causes a need for already installed components to be updated. Moreover, updates to host operating system may also evoke a need to update. To facilitate installation and updates of system, some kind of method of managing the project with its dependencies and managing distribution is needed. In the following sections, existing components and its dependencies will be described in more detail, and three methods for host-agnostic installation and managing dependencies will be discussed: custom installation scripts, virtualization and containerization  will be discussed.
\section{Components and its dependencies}
 The program responsible for first simulation step - SimBaD-CLI is written in \textit{C++} using \textit{Boost C++} libraries \cite{Schling2011}. In order to prevent installing tool chain needed to compile this program, pre-build binaries were used. As the program is linked dynamically, that is, necessary shared libraries are loaded at runtime and must be installed on host operating system. For example, for Linux-based operating systems, to find out all shared libraries required by program executable, the \textit{readelf} command was used. The output of this command is visible on listing \ref{list:readelf}. Those libraries, or their operating-system-specific equivalents, need to be distributed along with the executable to enable program to run. 
\begin{lstlisting}[label=list:readelf,caption=The output of readelf command (Tag column ommited), basicstyle=\footnotesize\ttfamily]
root@40fe8913a16f:/# readelf simbad-cli 
Type     Name/Value
(NEEDED) Shared library: [libboost_program_options.so.1.67.0]
(NEEDED) Shared library: [libstdc++.so.6]
(NEEDED) Shared library: [libm.so.6]
(NEEDED) Shared library: [libgcc_s.so.1]
(NEEDED) Shared library: [libc.so.6]
 ...
\end{lstlisting}

The second step of simulation, responsible for analyzing the stream data is an \textit{Apache Spark} program written in \textit{Scala}. \textit{Apache Spark} is a framework for distributed computing. Assuming that the program is already built to \textit{JAR} files, to run it, it is necessary to install spark ecosystem - proper versions of \textit{Java}, \textit{Apache Spark} and \textit{Apache Hadoop}, each with its additional dependencies.

The last step of simulation, responsible for visualizing the processed data is a set of \textit{Python} scripts. The script read data from \textit{CSV} and \textit{Parquet} files using \textit{Pyarrow} library, and then generate plots with \textit{Matplotlib} and \textit{Igraph}. Naturally, those libraries depend on another set of libraries, for example \textit{Pyarrow} depends directly on \textit{C++ Arrow} and \textit{Numpy}. 
\newpage
\section{Making the system host agnostic}
Making the programs cross-platform is a difficult tasks. There are several ways to make computer program run on arbitrary platforms.
\subsection{Installing all dependencies}
The first way is to compile the program natively, and install its third-party dependencies on the host system. This approach has several issues, first it is necessary to write installers or maintain packages for every system that we'd want to run the program on. Another issue is that the already existing configurations and installed programs or shared libraries will often have different versions the the ones needed to run program have wrong versions, and changing those versions requires user intervention, and even it it succeeds it may break existing applications. The same issue extends to uninstalling - if user wants to remove program, it's hard to remove its dependencies. Worst case scenario is when program or dependency is not compatible with host and cannot be installed, for example windows programs on Linux, or specific versions of library that are not compatible. Even if somehow all of these pitfalls were avoided, in the long run there are still OS updates that would need to be adjusted for. This leads to another issue - no versioning. Further development of system will lead to changes in its functionality, configuration and dependencies, and that creates a need for self-updating and patching capabilities. Though use of existing solutions like \textit{GNU Autoconf} on \textit{GNU\textbackslash Linux} distributions and \textit{Windows Installer} on Windows help with writing installers, this still does not solve the problem of having to write and maintain them \cite{MacKenzie2015, Wilson2004}.
The single most important advantage of this approach is performance - program run natively will have the least abstraction-related overhead, better access to host resources and in turn run faster. 
\subsection{Virtual Machines}
Another approach is virtualization - the process of running an separated environment on a layer separate from actual hardware. This process is enabled by a software called \textit{hypervisor}, that allows to create those separate environments, (also called \textit{Virtual Machines}) on host system. For \textit{SimBaD} project, this allows to create a template or an image of the environment with all of the dependencies and programs installed. From this image a virtual machine can be crated and wherever virtualization software is installed, the simulation process can be run. This solves a problem with writing separate install scripts for each operating system. Due to high degree of separation, it does not interfere with existing programs and libraries on host system and installing it does not break any existing dependencies. The virtual machine also solves the uninstalling problem - to completely remove the system from host user only needs to remove \textit{VM} image. 

Though it solves the "create once run anywhere" problem, this approach also has several drawbacks. Apart from all the programs and their dependencies, the image also contains whole operating system, and that increases the memory footprint. Apart from memory use, that simulation startup time also increases - whole another OS needs to boot before simulation can start. Additional layer of abstraction also adds some performance overhead. Another issue that, while it allows run the system in a single portable environments, virtualization of whole system makes harder to decouple its components. For example, if one for some reason (such as performance or decoupling) were to separate one of the simulation components into a dedicated machine, a custom virtual machine would have to be created. 
\subsection{Container}
Another solution to managing programs and their dependencies is containerization. It provides the ability to bundle the program and all of its dependencies - libraries, configuration files or binaries in such a way that in a single package (container) that makes it possible to run this programs across in different computer environments. There are several existing containerization solutions, but for the purpose of this comparison the most popular one \cite{Diamanti2018}, \textit{Docker} was chosen.

In addition to providing containers \textit{Docker} also allows to define abstractions of file systems and networks. In contrast to virtual machines it does not use hypervisor to separate and isolate processes from one another, but instead, it uses Linux kernel features, such as namespacing and control groups. This allows for applications running inside of Docker containers to outperform virtual-machines in almost all benchmarks, reaching near native performance \cite{Felter2015}. Docker uses layered file system - docker image is a stack of several read-only layers, where programs are installed, and on top of this stack is a single read-write layer, where programs can make changes \cite{DockerStorage}. Use of layer-file system enables docker to share read only layers between containers, for example, the same image of \textit{Debian Stable} with \textit{Python} and \textit{Boost} installed can be shared between two different containers, thus saving memory. Docker image is lightweight compared to \textit{VM} - basic alpine Linux image is only 5MB \cite{Alpine}. Another advantage is startup time - docker needs only few seconds to start, compared to few minutes in case of \textit{VM}. 
Docker has excellent development features. Each image is defined by \textit{Dockerfile} that specifies all the steps needed to create container. When changes are made to underlying component, the image can be build from source to reflect the changes. Apart of providing an environment to run program it can also provide an environment to build program, and connects those two environments with multi-stage builds. This feature allows to create layers with toolchain needed to compile program from source code, compile this program, remove the toolchain completely, take the resulting executable and place it in a layer that has everything needed to run the application. This allows to tie together build and release phases of development in single image, while also reducing its size. \textit{Docker} also has support for versioning with tags \cite{DockerTag} and a platform where developers can upload their images - \textit{DockerHub} \cite{DockerHub}. Such platform makes easy to distribute the images, in case of \textit{VM}, some kind of file hosting would be necessary. Another albeit, \textit{SimBaD} project specific advantage is that there are already several \textit{Dockerfiles} that define images needed to build or run system components.
The disadvantage of docker is that it relies heavily on \textit{GNU\textbackslash Linux} kernel features \cite{DockerOverview}. There is official support for docker on \textit{Windows} and \textit{macOS} machines, but on those systems \textit{Docker} runs on minimal \textit{GNU\textbackslash Linux} virtual machine, and that leads to the same performance drawbacks that is characteristic to virtual machines. 

From above comparison it is clearly visible that the best choice for making the system host agnostic is containerization using \textit{Docker} and as such it was chosen for the proposed system and the design of the system was aligned to use \textit{Docker} to its fullest capabilities.

